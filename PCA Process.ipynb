{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: http://vision.ucsd.edu/~iskwak/ExtYaleDatabase/ExtYaleB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "from PIL import Image\n",
    "from scipy.io import loadmat  \n",
    "from scipy import stats  \n",
    "from scipy.stats import multivariate_normal\n",
    "import re\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_images(data_path,target_folders,label_1_folder,reduce_height = 24,reduce_width = 21):\n",
    "    \"\"\"\n",
    "    This function reads in all images inside the specified folders, and label the images based on label_1_folder\n",
    "    data_path: the path of the folder where all the image folders reside in\n",
    "    target_folders: the target_folders to be read from\n",
    "    label_1_folder: images in the specified folders will be labeled with 1\n",
    "    \"\"\"\n",
    "    # label_1_folder = [9,21]\n",
    "    folder_paths = glob.glob(data_path + \"*\")\n",
    "    images = [] # Initialize a list to record images\n",
    "    labels = [] # Initialize a list to record labels\n",
    "    for folder_path in folder_paths:\n",
    "        index = int(folder_path[-2:]) # Get the index embeded in the folder path\n",
    "        if index in target_folders:\n",
    "            # Assign labels\n",
    "            if index in label_1_folder:\n",
    "                label =1\n",
    "            else:\n",
    "                label = 0\n",
    "\n",
    "            # Read in images and corresponding labels\n",
    "            img_paths = glob.glob(folder_path + \"/*.pgm\")\n",
    "            for img_path in img_paths: \n",
    "                if img_path.find(\"Ambient\")>0:\n",
    "                    img_paths.remove(img_path) # We do not want the \"Ambient\" image because it is a profile picture\n",
    "                else:\n",
    "                    # img = plt.imread(img_path) # Used to read image without resizing\n",
    "                    img_raw = Image.open(img_path) # Used when we need to resize the image (downsize in this case)\n",
    "                    img_reduce = img_raw.resize((reduce_width, reduce_height), Image.BILINEAR) # Resize the image\n",
    "                    img = np.array(img_reduce) # This step is necessary if we use Image.open()\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "def dark_pixel_curve(images,light_threshold = 20):\n",
    "    \"\"\"\n",
    "    Images are taken at different lighting conditions; thus some of the photos are dark. In order to avoid \n",
    "    the impact of the bad lighting conditions, we need to remove photos with large number of dark pixels. \n",
    "    This curve shows us the number of images to be removed at different thresholds (total number of pixels \n",
    "    that are below 20 in one image). It can help us select an appropriate threshold. \n",
    "    \"\"\"\n",
    "    height, width = images[0].shape # Get the dimension of one image\n",
    "    images_num = len(images)\n",
    "    thresh_list = range(100,height*width,100) # Threshold levels to be tested: from 100 to the total pixels\n",
    "    remove_list = []\n",
    "    for dark_pixel_threshold in thresh_list:\n",
    "        remove_count = 0\n",
    "        for i in range(0,images_num):\n",
    "            if sum(sum(images[i] < light_threshold)) > dark_pixel_threshold:\n",
    "                remove_count = remove_count + 1\n",
    "        remove_list.append(remove_count)\n",
    "    \n",
    "    plt.plot(thresh_list,remove_list)\n",
    "    plt.xlabel(\"Number of dark pixels in an image\")\n",
    "    plt.ylabel(\"Number of images to be removed from the list\")\n",
    "    plt.title(\"Select the right threshold level\")\n",
    "    \n",
    "def remove_dark_img(imgs,labels,dark_pixel_threshold,light_threshold = 20):\n",
    "    \"\"\"\n",
    "    This function remove images that have more dark pixels (<20) than our threshold\n",
    "    \"\"\"\n",
    "    remove_count = 0\n",
    "    imgs_num = len(imgs)\n",
    "    for i in range(imgs_num-1,0-1,-1):\n",
    "        if sum(sum(imgs[i] < light_threshold)) > dark_pixel_threshold:\n",
    "            del imgs[i]\n",
    "            del labels[i]\n",
    "            remove_count = remove_count + 1\n",
    "    print (remove_count,' images are below our threshold and thus removed from the list')\n",
    "    return imgs,labels,remove_count\n",
    "\n",
    "def plot_images(imgs,labels):\n",
    "    \"\"\"\n",
    "    Plot 25 images selected randomly\n",
    "    \"\"\"\n",
    "    ind = np.random.permutation(len(imgs))\n",
    "\n",
    "    # Create figure with 5x5 sub-plots.\n",
    "    fig, axes = plt.subplots(5, 5,figsize=(15,15))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.01)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat): \n",
    "        ax.imshow(imgs[ind[i]], plt.cm.gray)\n",
    "        xlabel = \"Anomaly: {0}\".format(labels[ind[i]])\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def show_anomaly_images(images,labels):\n",
    "    \"\"\"\n",
    "    This function randomly show 9 images with label 1\n",
    "    \"\"\"\n",
    "    anomaly_label_index = np.asarray(np.where(labels)).reshape(-1) # Get the indice of anomaly\n",
    "    anomaly_image = [images[i] for i in anomaly_label_index] # Extract the images labeled as anomaly\n",
    "    anomaly_label = [labels[i] for i in anomaly_label_index] # Extract the images labeled as anomaly\n",
    "    plot_images(anomaly_image,anomaly_label) # Show 9 images randomly\n",
    "    \n",
    "def plot_eigenfaces(pca_matrix,height, width):\n",
    "    \"\"\"\n",
    "    This function plot the eigenfaces based on the given PCA Matrix\n",
    "    \"\"\"\n",
    "    n_eigen = pca_matrix.shape[1]\n",
    "    # Define the layout of the plots\n",
    "    n_row = 4\n",
    "    n_col = n_eigen//n_row \n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(n_row, n_col,figsize=(15,15))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.01)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat): \n",
    "        ax.imshow(pca_matrix[:,i].reshape(height, width), plt.cm.gray)\n",
    "        xlabel = \"Eigenface: {0}\".format(i+1)\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "def mean_shift(components):\n",
    "    \"\"\"\n",
    "    This function applies mean shift to each component in the component matrix\n",
    "    The input components is a n*m matrix. Each row correspons to one component.\n",
    "    It is important to return the components' mean vector: we will need it in PCA reconstruction\n",
    "    \"\"\"\n",
    "    component_mean = np.mean(components,axis = 1)\n",
    "    shifted_components = (components.T - component_mean).T # Necessary to take transpose twice here\n",
    "    return shifted_components, component_mean\n",
    "\n",
    "def check_eigen(eigen_value, eigen_vector,cov_matrix):\n",
    "    \"\"\"\n",
    "    This function check the correctness of eigenvector & eigenvalue through the equation\n",
    "    cov_matrix * eigen_vector = eigen_value * eigen_vector\n",
    "    \"\"\"\n",
    "    for i in range(len(eigen_value)): \n",
    "        n = cov_matrix.shape[1]\n",
    "        eigv = eigen_vector[:,i].reshape(1,n).T \n",
    "        np.testing.assert_array_almost_equal(cov_matrix.dot(eigv), eigen_value[i] * eigv, decimal=6, err_msg='', verbose=True)\n",
    "        \n",
    "def plot_compare_after_reconst(img_matrix_reconst,imgs_matrix,height,width):\n",
    "    \"\"\"\n",
    "    This function compares the images reconstructed after PCA with their original one.\n",
    "    The shape of both image matrice in the input is n*m, where n is the number of components, \n",
    "    and m is the number of images.\n",
    "    \"\"\"\n",
    "    # Permutate through the image index\n",
    "    ind = np.random.permutation(imgs_matrix.shape[1])\n",
    "\n",
    "    # Create figure with multiple sub-plots.\n",
    "    fig, axes = plt.subplots(4, 4,figsize=(15,15))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.01)\n",
    "\n",
    "    # Initialize the counter of images\n",
    "    image_count = 0 \n",
    "\n",
    "    for i, ax in enumerate(axes.flat): \n",
    "        if i % 2 == 0:\n",
    "            image_count += 1\n",
    "            ax.imshow(imgs_matrix[:,ind[i]].reshape(height,width), plt.cm.gray)\n",
    "            xlabel = \"Example {0}: Original Image\".format(image_count)\n",
    "        else:\n",
    "            ax.imshow(img_matrix_reconst[:,ind[i-1]].reshape(height,width), plt.cm.gray)\n",
    "            xlabel = \"Example {0}: Reconstructed from PCA\".format(image_count)\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Images and Remove Over-shadowed Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the images to be read and the corresponding labels\n",
    "label_1_folder = [9,21]\n",
    "target_folders = range(1,22)\n",
    "data_path = \"Yale Face B/CroppedYale/\"\n",
    "\n",
    "# We also need to reduce the size of the image for the convenience of computation\n",
    "reduce_height = 24\n",
    "reduce_width = 21\n",
    "\n",
    "# Read the images and reduce the size\n",
    "images,labels = read_images(data_path,target_folders,label_1_folder,reduce_height,reduce_width)\n",
    "\n",
    "# Number of labels as \"Anomaly\" and Total Number of Labels\n",
    "sum(labels),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To evaluate the threshold of the dark pixels\n",
    "# dark_pixel_curve(images)\n",
    "\n",
    "imgs = images[:] # Create a copy\n",
    "# Eliminate the images and labels whose number of dark pixels are above the threshold\n",
    "# The threshold is determined based on the dark_pixel_curve() function above\n",
    "imgs,labels,remove_count = remove_dark_img(imgs,labels,180) \n",
    "\n",
    "plot_images(imgs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Randomly select and show anomalous images\n",
    "show_anomaly_images(imgs,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply PCA for Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the number of Principal Components we want to keep from the image\n",
    "n_components = 20\n",
    "\n",
    "# Find the dimension of one image\n",
    "height, width = imgs[0].shape\n",
    "num_imgs = len(imgs)\n",
    "height, width,num_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Images List to a 2-Dimensional Matrix\n",
    "Convert each image from 2D to 1D array, and each column of the new matrix will be one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the matrix to store the entire image list\n",
    "imgs_matrix = np.zeros((height*width,num_imgs)) \n",
    "\n",
    "# Iterate through each image, convert it into an array, and add to the imgs_matrix as a column\n",
    "for i in range(0,len(imgs)):\n",
    "    imgs_matrix[:,i] = imgs[i].reshape(height*width)\n",
    "imgs_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Mean-Shift\n",
    "We applied the Mean-Shift on each component before computing the Covariance Matrix. It is important to save the vector of the components' mean: we will use it when we reconstruct the data after we applied PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_matrix_shifted, component_mean = mean_shift(imgs_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Covariance Matrix of the Image Matrix\n",
    "The Covariance Matrix should be a symmetric square matrix with shape $n*n$, where $n$ is the row number of the Image Matrix, or **the number of the components**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(img_matrix_shifted)\n",
    "cov_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the eigenvectors and the corresponding eigenvalues based on the Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the eigen value and eigen vectors\n",
    "eigen_value, eigen_vector = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort the eigenvectors by decreasing eigenvalues\n",
    "# First make a list of (eigenvalue, eigenvector) tuples \n",
    "eig_pairs = [(np.abs(eigen_value[i]), eigen_vector[:,i]) for i in range(len(eigen_value))] \n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low \n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Convert the sorted eigen vector list to matrix form\n",
    "eigen_vector_sorted = np.zeros((height*width,n_components))\n",
    "for i in range(0,n_components):\n",
    "    eigen_vector_sorted[:,i] = eig_pairs[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the PCA Matrix and Visualize the Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cut the sorted eigenvectors by columns to get the transformational matrix for PCA\n",
    "pca_matrix = eigen_vector_sorted[:,:n_components]\n",
    "pca_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the eigenfaces with the pca matrix\n",
    "plot_eigenfaces(pca_matrix,height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the Face Images after PCA\n",
    "First we applies PCA on the image data matrix to downsize its dimensions. Then we reconstruct the image matrix through the PCA matrix and add the mean of each component back. Finally we plot several examples to compare the original face images with the reconstructed face images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the transformed image\n",
    "# Shape of pca_matrix: n * k\n",
    "# Shape of imgs_matrix: n * m\n",
    "# Shape of the transformed face image matrix: k * m\n",
    "img_pca_tranf = pca_matrix.T.dot(img_matrix_shifted)\n",
    "\n",
    "# Reconstruct through PCA Matrix and Mean Vector\n",
    "# Shape of the reconstructed face image matrix: n * m\n",
    "# component_mean is a vector and we need to convert it to a one-column matrix for the addition\n",
    "img_matrix_reconst = pca_matrix.dot(img_pca_tranf) + component_mean.reshape(height*width,1)\n",
    "\n",
    "# Plot the original images and their reconstructed version for comparison\n",
    "plot_compare_after_reconst(img_matrix_reconst,imgs_matrix,height,width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
