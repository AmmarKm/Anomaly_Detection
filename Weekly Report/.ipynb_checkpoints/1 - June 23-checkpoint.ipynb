{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Report - June 23\n",
    "## Summary of Contents\n",
    "- Goals\n",
    "- Results & Findings\n",
    "- Plan of the Next Week\n",
    "- Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "My goals of the week include:\n",
    "- Implement the following four **Anomaly Detectors** and do comparison\n",
    "    - Detector based on the Construction Error with PCA \n",
    "    - Detector based on the Multivariate-Gaussian Distribution with PCA\n",
    "    - Detector based on the Construction Error with Deep Autoencoder\n",
    "    - Detector based on the Multivariate-Gaussian Distribution with Deep Autoencoder\n",
    "- Apply the same evluation to different dataset to test if the conclusion can be generalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Findings\n",
    "### Dataset 1: Face Data from Yale\n",
    "The results of Construction Error-based methods work well in the dataset, and in comparison, PCA-based method achieves a better result than the Deep Autoencoder-based result. However, I highly doubt that this may be due to the small size of the dataset (there are just around 600 images in the dataset)\n",
    "\n",
    "#### Comparison two Construction Error-based methods\n",
    "> Table of Results (Precision @k) in the Test set\n",
    "\n",
    "|Method|Precision @ K = 50|\n",
    "|------|-------------|\n",
    "|Construction Error with PCA (N = 50)|100%|\n",
    "|Construction Error with PCA (N = 20)|70%|\n",
    "|Construction Error with Deep Autoencoder|65%|\n",
    "\n",
    "*Note*: the `N` in the table is the number of Principal Components selected during encoding. \n",
    "\n",
    "<br>\n",
    "\n",
    "> Plots of Reconstruction Error from each encoding methods\n",
    "\n",
    "The following plots show the data points sorted according to their reconstruction error. The points are colored based on their labels: anomaly points are black and normal points are yellow. \n",
    "\n",
    "Clearly, **in all of the three methods, most of the anomaly points have high construction error**, which is desireable.\n",
    "\n",
    "Construction Error with PCA (N = 50): \n",
    "![PCA_N=50](Screenshots/623_re_pca_50.png)\n",
    "\n",
    "Construction Error with PCA (N = 20): \n",
    "![PCA_N=20](Screenshots/623_re_pca_20.png)\n",
    "\n",
    "Construction Error with Deep Autoencoder: \n",
    "![DA](Screenshots/623_re_da.png)\n",
    "\n",
    "#### Failure of Gaussian-based methods\n",
    "With PCA-encoder, the Gaussian method fails to identify the Anoamly. Below is a plot of data points sorted according to their Probability in the Gaussian Distribution. **Ideally, the anomaly points should have very low probability**, as the distribution is fitted only to the normal data. However, the long and flat tail makes it very diffcult to detect anomalies precisely. \n",
    "\n",
    "The Precision @ 50 on the test set is only 4.0%\n",
    "\n",
    "![GA-PCA](Screenshots/623_ga_pca.png)\n",
    "\n",
    "As for the Deep Autoencoder, there is a big problem: **the covariance of the encoded matrix become singular**, which means the Gaussian method becomes un-usable. This problem happens to both the Face dataset and the MNIST hand-writing digits dataset. The cause of the problem is still un-known. Dusan thought a potential reason is the training data is not big enough, but I used an entire MNIST dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: MNIST\n",
    "The MNIST dataset contains an (almost) equal amount of hand-written photos of 10 digits. I first selected the photos of digit 0 as the anomaly, and others as normal. The result was very bad. Later I changed the target to the digit 2 from the digit 0, and the result became very good. \n",
    "\n",
    "#### Comparison two Construction Error-based methods\n",
    "> Table of Results (Precision @k) in the Test set\n",
    "\n",
    "|Method|Precision @ K = 50|\n",
    "|------|-------------|\n",
    "|Construction Error with PCA (N = 200)|72%|\n",
    "|Construction Error with Deep Autoencoder|86%|\n",
    "\n",
    "*Note*: the `N` in the table is the number of Principal Components selected during encoding. \n",
    "\n",
    "<br>\n",
    "\n",
    "> Plots of Reconstruction Error from each encoding methods\n",
    "\n",
    "The following plots show the data points sorted according to their reconstruction error. The points are colored based on their labels: anomaly points are black and normal points are yellow. \n",
    "\n",
    "Clearly, **in all of the three methods, most of the anomaly points have high construction error**, which is desireable.\n",
    "\n",
    "Construction Error with PCA: \n",
    "![PCA](Screenshots/623_re_pca_mnist.png)\n",
    "\n",
    "Construction Error with Deep Autoencoder: \n",
    "![DA](Screenshots/623_re_da_mnist.png)\n",
    "\n",
    "\n",
    "#### Failure of Gaussian-based methods\n",
    "The Gaussian-based methods fail in this dataset as well. \n",
    "\n",
    "In the context of autoencoder, the problem remains the same: singular covariance prevents the use of gaussian distribution. \n",
    "\n",
    "In PCA, the problem is strange: all of the data points have 0 probability (as shown below). I am still probing for the cause of the problem. Probably it is due to a bug in the code. \n",
    "\n",
    "![GA-PCA-mnist](Screenshots/623_ga_pca_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of the Next Week\n",
    "1. For PCA-based method, I want to do quantative test to evaluate the effect of N (number of PC selected) on the final result (Precision @ K)\n",
    "2. For Gaussian and Deep Autoencoder-based method, I want to identify the cause(s) of the singularity problem, and how to solve it. \n",
    "3. For Deep Autoencoder-based methods in general, I want to test different configurations (number of layers, layer size, dropout, etc)\n",
    "4. I will find 1-2 more datasets and compare the performance of the four detectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendice\n",
    "### Links to my code\n",
    "- [Work on the Yale Faces Dataset](https://github.com/Ivan-Zhou/Anomaly_Detection/tree/master/Yale_Faces_Data)\n",
    "    - [PCA & Reconstruction Error (N = 50)](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/Yale_Faces_Data/PCA_Reconstruction_Error_k%3D50.ipynb)\n",
    "    - [PCA & Reconstruction Error (N = 20)](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/Yale_Faces_Data/PCA_Reconstruction_Error_k%3D20.ipynb)\n",
    "    - [PCA & Gaussian](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/Yale_Faces_Data/PCA_Multivariate%20Gaussian.ipynb)\n",
    "    - [Deep Autoencoder - Training](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/Yale_Faces_Data/Autoencoder_training_deep.py)\n",
    "    - [Deep Autoencoder - Two Methods](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/Yale_Faces_Data/Autoencoder%20Anomaly%20Detection-Deep.ipynb)\n",
    "- [Work on the MNIST](https://github.com/Ivan-Zhou/Anomaly_Detection/tree/master/MNIST)\n",
    "    - [PCA & Reconstruction Error - 0 as Target Anomaly](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/PCA_Reconstruction_Error_Target_0.ipynb)\n",
    "    - [PCA & Reconstruction Error - 2 as Target Anomaly](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/PCA_Reconstruction_Error_Target_2.ipynb)\n",
    "    - [PCA & Gaussian](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/PCA_Gaussian_Based_Model_Target_2.ipynb)\n",
    "    - [Deep Autoencoder - Training](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/autoencoder_training.py)\n",
    "    - [Deep Autoencoder & Reconstruction Error](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/Autoencoder_Reconstruction_Error.ipynb)\n",
    "    - [Deep Autoencoder & Gaussian](https://github.com/Ivan-Zhou/Anomaly_Detection/blob/master/MNIST/Autoencoder_Multivariate_Gaussian.ipynb)\n",
    "    \n",
    "### Sample Images from PCA & Autoencoder\n",
    "#### Faces Data - Decoded from PCA\n",
    "![face_pca](Screenshots/623_decoded_pca_faces.png)\n",
    "\n",
    "#### Faces Data - Decoded from Deep Autoencoder\n",
    "![face_da](Screenshots/623_decoded_da_faces.png)\n",
    "\n",
    "#### MNIST Data - Decoded from PCA\n",
    "![mnist_pca](Screenshots/623_decoded_pca_mnist.png)\n",
    "\n",
    "#### MNIST Data - Decoded from Auto Autoencoder\n",
    "![mnist_pca](Screenshots/623_decoded_da_mnist.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
